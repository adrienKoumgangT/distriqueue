\chapter{Technology Stack And Implementation Details}\label{ch:technology-stack-and-implementation-details}


\section{Project Structure}\label{sec:project-structure}

The project consists primarily of these files:
\begin{itemize}
    \item \textbf{orchestrator/}: Erlang/OTP application
    \item \textbf{gateway/}: Java Spring Boot API
    \item \textbf{workers/python-worker/}: Python worker implementation
    \item \textbf{workers/java-worker/}: Java worker implementation
\end{itemize}


\section{Erlang/OTP Orchestrator}\label{sec:erlang-otp}

\subsection{Shared Record Definitions (.hrl)}\label{subsec:hrl-files}
To prevent inclusion explosions and maintain a single source of truth across the cluster, a shared header file (\texttt{distriqueue.hrl}) is utilized.
\begin{lstlisting}[language=Erlang, caption={Shared Worker Record},label={lst:shared-worker-record}]
-record(worker, {
  id :: binary(),
  type :: binary(),
  status :: active | idle | unresponsive,
  capacity :: integer(),
  current_load :: integer(),
  last_heartbeat :: integer()
}).
\end{lstlisting}


\subsection{Pro Routing Strategy}\label{subsec:routing}

The load balancer inside \texttt{router.erl} implements an identity-agnostic, capacity-aware routing algorithm:

\begin{lstlisting}[language=Erlang, caption={Dynamic Least-Loaded Type Routing},label={lst:dynamic-least-loaded-type-routing}]
select_least_loaded_by_type(Type, _State) ->
  case dq_worker_pool:get_workers_by_type(Type) of
    [] -> <<"default_worker">>;
    Workers ->
      {BestWorkerId, _} = lists:foldl(
        fun(W, {AccId, AccRatio}) ->
          Cap = case W#worker.capacity of 0 -> 1; C -> C end,
          Ratio = W#worker.current_load / Cap,
          if Ratio < AccRatio -> {W#worker.id, Ratio};
             true -> {AccId, AccRatio}
          end
        end, {<<"none">>, 999999.0}, Workers),
      BestWorkerId
  end.
\end{lstlisting}


\section{Polyglot Worker Framework (Python)}\label{sec:python-worker}

The worker framework utilizes the Strategy Pattern to dynamically map incoming payloads to execution logic.

\begin{lstlisting}[language=Python, caption={Python Strategy Pattern for Jobs},label={lst:python-strategy-pattern-for-job}]
class TransformationJobHandler(JobHandler):
    def can_handle(self, job_type: str) -> bool:
        return job_type in ['transform', 'uppercase', 'reverse']

    def execute(self, job: Dict[str, Any]) -> Dict[str, Any]:
        payload = job.get('payload', {})
        operation = payload.get('operation', 'uppercase')
        data = payload.get('data', {})
        
        if operation == 'reverse':
            transformed = {k[::-1]: str(v)[::-1] for k, v in data.items()}
            return {'transformed': transformed}
\end{lstlisting}


\section{Database Schema}\label{sec:database-schema}

\begin{lstlisting}[language=SQL, caption={Database Schema}, label={lst:database-schema}]
CREATE TABLE jobs (
    id VARCHAR(36) PRIMARY KEY,
    type VARCHAR(50) NOT NULL,
    priority VARCHAR(20) NOT NULL,
    status VARCHAR(20) NOT NULL,
    worker_id VARCHAR(100),
    payload CLOB,
    result CLOB,
    error_message VARCHAR(1000),
    retry_count INT DEFAULT 0,
    max_retries INT DEFAULT 3,
    execution_timeout INT DEFAULT 300,
    created_at TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    updated_at TIMESTAMP,
    metadata CLOB,
    parent_job_id VARCHAR(36),
    callback_url VARCHAR(500),
    tags VARCHAR(500),
    queue_name VARCHAR(50),
    processing_node VARCHAR(100),
    version BIGINT
);

CREATE INDEX idx_job_status ON jobs(status);
CREATE INDEX idx_job_type ON jobs(type);
CREATE INDEX idx_job_priority ON jobs(priority);
CREATE INDEX idx_job_created ON jobs(created_at);
CREATE INDEX idx_job_worker ON jobs(worker_id);
\end{lstlisting}



\section{Quick Start Guide}\label{sec:quick-start-guide}

\subsection{Access Points}\label{subsec:access-points}

\begin{tabular}{l l l}
    Service & Adrien0 (10.2.1.11) & Adrien1 (10.2.1.12) \\
    API Gateway & http://10.2.1.11 & http://10.2.1.12 \\
    Load Balancer & http://10.2.1.11 (port 80) & - \\
    H2 Console & http://10.1.2.11:8082/h2-console & http://10.1.2.12:8082/h2-console \\
    RabbitMQ UI & http://10.1.2.11:15672 & http://10.1.2.12:15672 \\
    Node Exporter & http://10.2.1.11:9100 & http://10.2.1.4:9100 \\
\end{tabular}


\textbf{Credentials}:
\begin{itemize}
    \item RabbitMQ: admin / admin
    \item H2 Database: sa / (empty)
    \item Redis: (empty)
\end{itemize}


\section{Testing and Benchmarks}\label{sec:testing-and-benchmarks}


\subsection{Unit Testing (EUnit)}\label{subsec:unit-testing-(eunit)}

The Erlang orchestrator utilizes the EUnit testing framework to ensure the internal logic of the system is sound.
Test suites were written for modules such as \texttt{dq\_worker\_pool.erl} to verify worker registration, capacity tracking, and selection strategies.
\begin{lstlisting}[language=Erlang, caption={EUnit Worker Pool Test},label={lst:eunit-worker-pool-test}]
test_select_worker() ->
  ok = dq_worker_pool:register_worker(<<"worker3">>, <<"python">>, 5, 0),
  ok = dq_worker_pool:register_worker(<<"worker4">>, <<"python">>, 5, 3),
  {ok, LeastLoaded} = dq_worker_pool:select_worker(<<"python">>, least_loaded),
  ?assertEqual(<<"worker3">>, LeastLoaded).
\end{lstlisting}


\subsection{Integration Testing}\label{subsec:integration-testing}

End-to-end integration tests were conducted by submitting complex JSON payloads via cURL to the Spring Boot Gateway, observing the AMQP transmission, and verifying the Erlang routing.

\textbf{Test Case: Nested Mathematical Aggregation}
A job requesting the \texttt{aggregate} operation on a large array of numbers was submitted.
The system dynamically routed the task to a Java worker (due to lower load than the Python worker).
The complex nested result (\texttt{\{ "aggregates": \{ "average": 473, "max": 1024 \} \}}) was successfully parsed by Erlang using \texttt{jsx:encode} and broadcast back to the Gateway.


\subsection{Performance Benchmarks}\label{subsec:performance-benchmarks}

\begin{itemize}
    \item \textbf{End-to-End Latency}: The round trip (Gateway $\rightarrow$ RabbitMQ $\rightarrow$ Erlang Router $\rightarrow$ Worker Execution $\rightarrow$ Erlang HTTP $\rightarrow$ RabbitMQ Broadcast $\rightarrow$ Gateway) averaged \textbf{375 milliseconds} for standard computational tasks.
    \item \textbf{Queue Time}: Overhead spent in RabbitMQ and Erlang's routing queue averaged roughly 130 ms under a normal load.
\end{itemize}


\subsection{Fault Tolerance Simulation}\label{subsec:fault-tolerance-simulation}

Chaos engineering techniques were applied by manually terminating worker processes mid-execution.
The \texttt{health\_monitor.erl} successfully detected the missing heartbeats, marked the nodes as unresponsive, and the orchestrator requeued the pending tasks according to the \texttt{max\_retries} defined in the job payload.
